# -*- coding: utf-8 -*-
"""IS603-Mid report.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yGGn0FFeAQkXmH43vMKFUAqpq2Y-263g
"""

import pandas as pd

data = pd.read_csv('/content/Netflix_Userbase.csv')

data.head(20)

data['Subscription Type'].unique()

data.info

for i in data.columns:
  print(data[i],"-",data[i].isna().sum())

data["Country"].unique()

len(data)

country=[]
basic_total=[]
for j in data["Country"].unique():
    country.append(j)
    count=0
    for i in range(0,len(data)):
        if data["Subscription Type"][i]=='Basic' and data["Country"][i]==j:
            count=count+1
    basic_total.append(count)

country=[]
basic_total=[]
for j in data["Country"].unique():
    country.append(j)
    count=0
    for i in range(0,len(data)):
        if data["Subscription Type"][i]=='Basic' and data["Country"][i]==j:
            count=count+1
    basic_total.append(count)


country=[]
stan_total=[]
for j in data["Country"].unique():
    country.append(j)
    count=0
    for i in range(0,len(data)):
        if data["Subscription Type"][i]=='Standard' and data["Country"][i]==j:
            count=count+1
    stan_total.append(count)

country=[]
pre_total=[]
for j in data["Country"].unique():
    country.append(j)
    count=0
    for i in range(0,len(data)):
        if data["Subscription Type"][i]=='Premium' and data["Country"][i]==j:
            count=count+1
    pre_total.append(count)

print(country)
print(basic_total)
print(country)
print(stan_total)
print(country)
print(pre_total)

country=[]
basic_total=[]
stan_total=[]
premium_total=[]
for j in data["Country"].unique():
    country.append(j)
    count1=0
    count2=0
    count3=0
    for i in range(0,len(data)):
        if data["Subscription Type"][i]=='Basic' and data["Country"][i]==j:
            count1=count1+1
        if data["Subscription Type"][i]=='Standard' and data["Country"][i]==j:
            count2=count2+1
        if data["Subscription Type"][i]=='Premium' and data["Country"][i]==j:
            count3=count3+1
    basic_total.append(count1)
    stan_total.append(count2)
    premium_total.append(count3)

print(country)
print(basic_total)
print(country)
print(stan_total)
print(country)
print(premium_total)

import matplotlib.pyplot as plt
plt.figure(figsize=(10,5))
plt.bar(country,basic_total)
plt.title("Basic Subscription type count for every country")
plt.xlabel('Country')
plt.ylabel('Count')
plt.show()

# Library Import(numpy and matplotlib)
import numpy as np
import matplotlib.pyplot as plot

# Make a data definition
_team = country
X_axis = np.arange(len(_team))

plot.figure(figsize=(15,5))
# Multiple colors of bars
plot.bar(X_axis -0.2, basic_total, width=0.2,
        label = 'Basic', color='r')
plot.bar(X_axis, stan_total, width=0.2,
        label = 'Standard', color='y')
plot.bar(X_axis +0.2, premium_total, width=0.2,
        label = 'Premium', color='g')

plot.title("Subscription in each country")

# Xticks
plot.xticks(X_axis, _team)

# Adding legend to the plot
plot.legend()

# Display the plot
plot.show()

data.head()

data['Plan Duration'].unique()

from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder(handle_unknown='ignore')

import numpy as np

data1=data

data1.head()

import matplotlib.pyplot as plt

basic_count, standard_count, premium_count=0,0,0
for i in range(len(data1['Subscription Type'])):
  if data1['Subscription Type'][i]=='Basic':
    basic_count=basic_count+1
  elif data1['Subscription Type'][i]=='Standard':
    standard_count=standard_count+1
  elif data1['Subscription Type'][i]== 'Premium':
    premium_count=premium_count+1

print(basic_count, standard_count, premium_count)

labels = 'Basic', 'Standard', 'Premium'
sizes = [basic_count, standard_count, premium_count]


# only "explode" the 2nd slice (i.e. 'Hogs')
explode = (0, 0.1, 0)
#add colors
colors = ['grey','brown','green']
fig1, ax1 = plt.subplots()
ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',
        shadow=True, startangle=90)
# Equal aspect ratio ensures that pie is drawn as a circle
ax1.axis('equal')
plt.tight_layout()
plt.show()

from datetime import datetime

data1['Last Payment Date'][0]

for i in range(0,len(data['Last Payment Date'])):
  data1['Last Payment Date'][i] = datetime.strptime(data1['Last Payment Date'][i], '%d-%m-%y')
  timestamp = data1['Last Payment Date'][i].timestamp()

for i in range(0,len(data['Join Date'])):
  data1['Join Date'][i] = datetime.strptime(data1['Join Date'][i], '%d-%m-%y')
  #timestamp = data1['Join Date'][i].timestamp()

data1.head()

data1['duration']=data1['Last Payment Date']- data1['Join Date']

data1.head()

data1=data1.drop(['User ID','Join Date','Last Payment Date','Plan Duration'],axis=1)

data1.head()

data1 = pd.get_dummies(data1, columns=['Gender'], prefix=['gender'], drop_first=False)

data1.head()

data1=pd.get_dummies(data1, columns=['Country'], drop_first=True)

data1=pd.get_dummies(data1,columns=['Device'],drop_first=True)

data1.head()

mapping={'Basic':0, 'Standard':1,'Premium':2}

data1['Subscription Type']=data1['Subscription Type'].map(mapping)

for i in range(0,len(data['duration'])):
  duration_series = pd.Series(pd.to_timedelta(data1['duration'][i]))
  data1['duration'][i] = duration_series.dt.total_seconds().astype(int)

data1.head()

data['duration']=data1['duration'].astype(int)

X= data1.loc[:, data1.columns != 'Subscription Type']

from sklearn.preprocessing import StandardScaler

y=data1['Subscription Type']

from sklearn.model_selection import train_test_split

len(X)

scaler = StandardScaler()
X=scaler.fit_transform(X)

from sklearn.cluster import KMeans
clf = KMeans(n_clusters = 3, random_state = 0, n_init='auto')
y_kmeans=clf.fit(X)



from sklearn.decomposition import PCA

pca_reduced=PCA(n_components=2)
pca_reduced.fit(X)
x=pca_reduced.transform(X)

import matplotlib.pyplot as plt

import matplotlib.patches as mpatches
##Plot the scatter plot graph using kmeans labels
plt.figure(figsize=(10,10))
#plt.scatter(x[:,0],x[:,1],c=clf.labels_,cmap='plasma')
plt.scatter(x[:,0],x[:,1],c=y,cmap='plasma')
plt.xlabel('pc1')
plt.ylabel('pc2')

yellowpatch=mpatches.Patch(color='yellow',label='Premium')
greenpatch=mpatches.Patch(color='green',label='basic')
violetpatch=mpatches.Patch(color='blue',label='Standard')

plt.legend(handles=[yellowpatch,greenpatch,violetpatch])

##Plot the scatter plot graph using kmeans labels
plt.figure(figsize=(10,10))
plt.scatter(x[:,0],x[:,1],c=clf.labels_,cmap='viridis')
#plt.scatter(x[:,0],x[:,1],c=y,cmap='plasma')
plot.title("Subscription in each country")
plt.xlabel('pc1')
plt.ylabel('pc2')



from sklearn.cluster import KMeans
clf = KMeans(n_clusters = 3, random_state = 0, n_init='auto')
y_kmeans=clf.fit(x)

##Plot the scatter plot graph using kmeans labels
plt.figure(figsize=(18,15))
plt.scatter(x[:,0],x[:,1],c=clf.labels_,cmap='viridis')
#plt.scatter(x[:,0],x[:,1],c=y,cmap='plasma')
plot.title("Clustering of Dataset")
plt.xlabel('pc1')
plt.ylabel('pc2')

X_train, X_test, y_train, y_test = train_test_split(X,y)

X_train, X_test, y_train, y_test = X.iloc[0:2000,:], X.iloc[2000:2500,:], y.iloc[0:2000], y.iloc[2000:2500]

scaler = StandardScaler()
X_train=scaler.fit_transform(X_train)

scaler = StandardScaler()
_X_test=scaler.fit_transform(X_test)

from sklearn.linear_model import LogisticRegression

logistic_regrssion=LogisticRegression()
logistic_regrssion.fit(X_train,y_train)

y_pred_lr=logistic_regrssion.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy_score_lr=accuracy_score(y_test,y_pred_lr)
accuracy_score_lr

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test,y_pred_lr)

from sklearn.tree import DecisionTreeClassifier

decision_tree = DecisionTreeClassifier(random_state=0)
decision_tree.fit(X_train,y_train)

y_pred_dt=decision_tree.predict(X_test)

accuracy_score_dt=accuracy_score(y_test,y_pred_dt)
accuracy_score_dt

confusion_matrix(y_test,y_pred_dt)

from sklearn.svm import SVC

svm=SVC(kernel='rbf')
svm.fit(X_train,y_train)

y_pred_svm=svm.predict(X_test)

accuracy_score_svm=accuracy_score(y_test,y_pred_svm)
accuracy_score_svm



confusion_matrix(y_test,y_pred_svm)

plot.figure(figsize=(10,5))
x_label=['Logistic Regression','Decision Tree','SVM']
y_label=[accuracy_score_lr,accuracy_score_dt,accuracy_score_svm]
plot.bar(x_label,y_label)
plot.title("Accuracy Scores")
plot.xlabel('Model')
plot.ylabel('Accuracy')
plot.ylim(0,1)
plot.show()

X.shape

from tensorflow.keras.activations import relu, sigmoid, softmax, tanh

# example of a model defined with the sequential api
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
# define the model
model = Sequential()
model.add(Dense(16, input_shape=(16,)))
model.add(Dense(8), activation='relu')
model.add(Dense(4), activation='relu')
model.add(Dense(1), activation='sigmoid')

y.unique()

model = Sequential()
model.add(Dense(9, activation='relu', kernel_initializer='he_normal', input_shape=(16,)))
model.add(Dense(6, activation='relu', kernel_initializer='he_normal'))
model.add(Dense(3, activation='softmax'))

model.compile(optimizer='adam', loss='categorial_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)

loss, acc = model.evaluate(X_test, y_test, verbose=0)

print('Test Accuracy: %.3f' % acc)

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AffinityPropagation
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")
import plotly as py
import plotly.graph_objs as go
import os
py.offline.init_notebook_mode(connected = True)
#print(os.listdir("../input"))
import datetime as dt
import missingno as msno
plt.rcParams['figure.dpi'] = 140
df = pd.read_csv('Netflix_Userbase.csv')

df['count'] = 1

# Lets retrieve just the first country
df['first_country'] = df['Country'].apply(lambda x: x.split(",")[0])
df['first_country'].head()

# Reducing name length

df['first_country'].replace('United States', 'USA', inplace=True)
df['first_country'].replace('United Kingdom', 'UK',inplace=True)

data = df.groupby('first_country')[['first_country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]
data = data['first_country']


df_heatmap = df.loc[df['first_country'].isin(data)]

# Many productions have several countries listed - this will skew our results , we'll grab the first one mentioned


# Rating ages from this notebook: https://www.kaggle.com/andreshg/eda-beginner-to-expert-plotly (thank you!)

ratings_ages = {
    'TV-PG': 'Older Kids',
    'TV-MA': 'Adults',
    'TV-Y7-FV': 'Older Kids',
    'TV-Y7': 'Older Kids',
    'TV-14': 'Teens',
    'R': 'Adults',
    'TV-Y': 'Kids',
    'NR': 'Adults',
    'PG-13': 'Teens',
    'TV-G': 'Kids',
    'PG': 'Older Kids',
    'G': 'Kids',
    'UR': 'Adults',
    'NC-17': 'Adults'
}

df['target_ages'] = df['Subscription Type'].replace(ratings_ages)
df['target_ages'].unique()


fig, ax = plt.subplots(1, 1, figsize=(12, 12))

country_order2 = ['USA', 'UK', 'Canada', 'Brazil', 'France', 'Spain',
       'Mexico', 'Australia', 'Italy', 'Germany']

age_order = ['Kids','Older Kids','Teens','Adults']

sns.heatmap(df_heatmap.loc[age_order,country_order2],cmap=cmap,square=True, linewidth=2.5,cbar=False,
            annot=True,fmt='1.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={"fontsize":12})

ax.spines['top'].set_visible(True)


fig.text(.99, .725, 'Target ages proportion of total content by country', fontweight='bold', fontfamily='serif', fontsize=15,ha='right')
fig.text(0.99, 0.7, 'Here we see interesting differences between countries. Most shows in India are targeted to teens, for instance.',ha='right', fontsize=12,fontfamily='serif')

ax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=11)
ax.set_xticklabels(ax.get_xticklabels(), fontfamily='serif', rotation=90, fontsize=11)

ax.set_ylabel('')
ax.set_xlabel('')
ax.tick_params(axis=u'both', which=u'both',length=0)
plt.tight_layout()
plt.show()